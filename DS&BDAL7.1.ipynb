{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c13a317-8103-4866-962a-1754c565b83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20b5f730-edd7-4b44-b88f-2b51c5a71840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Document\n",
    "file_path = 'sample.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cada08b4-7f18-4a17-bc87-44013f256fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'text': [text]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d8c1e87-8a9f-435b-93fa-12056b8183ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_doc = df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03a53ef3-e0ae-4b95-86ef-4a5539f8c850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Text',\n",
       " 'analytics',\n",
       " 'is',\n",
       " 'the',\n",
       " 'process',\n",
       " 'of',\n",
       " 'analyzing',\n",
       " 'unstructured',\n",
       " 'text',\n",
       " 'data',\n",
       " 'to',\n",
       " 'derive',\n",
       " 'meaningful',\n",
       " 'insights',\n",
       " '.',\n",
       " 'It',\n",
       " 'involves',\n",
       " 'various',\n",
       " 'preprocessing',\n",
       " 'steps',\n",
       " 'such',\n",
       " 'as',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'POS',\n",
       " 'tagging',\n",
       " ',',\n",
       " 'stop',\n",
       " 'words',\n",
       " 'removal',\n",
       " ',',\n",
       " 'stemming',\n",
       " ',',\n",
       " 'and',\n",
       " 'lemmatization',\n",
       " '.',\n",
       " 'Once',\n",
       " 'the',\n",
       " 'text',\n",
       " 'is',\n",
       " 'preprocessed',\n",
       " ',',\n",
       " 'we',\n",
       " 'can',\n",
       " 'calculate',\n",
       " 'term',\n",
       " 'frequency',\n",
       " 'and',\n",
       " 'inverse',\n",
       " 'document',\n",
       " 'frequency',\n",
       " 'to',\n",
       " 'represent',\n",
       " 'the',\n",
       " 'document',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokens = word_tokenize(sample_doc)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af6e42ef-707f-49e5-a514-cfa48a796573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Text', 'NN'),\n",
       " ('analytics', 'NNS'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('process', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('analyzing', 'VBG'),\n",
       " ('unstructured', 'JJ'),\n",
       " ('text', 'NN'),\n",
       " ('data', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('derive', 'VB'),\n",
       " ('meaningful', 'JJ'),\n",
       " ('insights', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('involves', 'VBZ'),\n",
       " ('various', 'JJ'),\n",
       " ('preprocessing', 'VBG'),\n",
       " ('steps', 'NNS'),\n",
       " ('such', 'JJ'),\n",
       " ('as', 'IN'),\n",
       " ('tokenization', 'NN'),\n",
       " (',', ','),\n",
       " ('POS', 'NNP'),\n",
       " ('tagging', 'NN'),\n",
       " (',', ','),\n",
       " ('stop', 'VB'),\n",
       " ('words', 'NNS'),\n",
       " ('removal', 'JJ'),\n",
       " (',', ','),\n",
       " ('stemming', 'VBG'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('lemmatization', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Once', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('text', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('preprocessed', 'VBN'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('calculate', 'VB'),\n",
       " ('term', 'NN'),\n",
       " ('frequency', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('inverse', 'JJ'),\n",
       " ('document', 'NN'),\n",
       " ('frequency', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('represent', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('document', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS Tagging\n",
    "pos_tags = pos_tag(tokens)\n",
    "pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79feeb61-a1a9-4ca1-bab7-c32939268dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Text',\n",
       " 'analytics',\n",
       " 'process',\n",
       " 'analyzing',\n",
       " 'unstructured',\n",
       " 'text',\n",
       " 'data',\n",
       " 'derive',\n",
       " 'meaningful',\n",
       " 'insights',\n",
       " '.',\n",
       " 'involves',\n",
       " 'various',\n",
       " 'preprocessing',\n",
       " 'steps',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'POS',\n",
       " 'tagging',\n",
       " ',',\n",
       " 'stop',\n",
       " 'words',\n",
       " 'removal',\n",
       " ',',\n",
       " 'stemming',\n",
       " ',',\n",
       " 'lemmatization',\n",
       " '.',\n",
       " 'text',\n",
       " 'preprocessed',\n",
       " ',',\n",
       " 'calculate',\n",
       " 'term',\n",
       " 'frequency',\n",
       " 'inverse',\n",
       " 'document',\n",
       " 'frequency',\n",
       " 'represent',\n",
       " 'document',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stop Words Removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65205a54-cc10-4b16-98da-3e5eb2c793a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text',\n",
       " 'analyt',\n",
       " 'process',\n",
       " 'analyz',\n",
       " 'unstructur',\n",
       " 'text',\n",
       " 'data',\n",
       " 'deriv',\n",
       " 'meaning',\n",
       " 'insight',\n",
       " '.',\n",
       " 'involv',\n",
       " 'variou',\n",
       " 'preprocess',\n",
       " 'step',\n",
       " 'token',\n",
       " ',',\n",
       " 'po',\n",
       " 'tag',\n",
       " ',',\n",
       " 'stop',\n",
       " 'word',\n",
       " 'remov',\n",
       " ',',\n",
       " 'stem',\n",
       " ',',\n",
       " 'lemmat',\n",
       " '.',\n",
       " 'text',\n",
       " 'preprocess',\n",
       " ',',\n",
       " 'calcul',\n",
       " 'term',\n",
       " 'frequenc',\n",
       " 'invers',\n",
       " 'document',\n",
       " 'frequenc',\n",
       " 'repres',\n",
       " 'document',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
    "stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eac3da8-b7a6-473e-9c72-338e448f93ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Text',\n",
       " 'analytics',\n",
       " 'process',\n",
       " 'analyzing',\n",
       " 'unstructured',\n",
       " 'text',\n",
       " 'data',\n",
       " 'derive',\n",
       " 'meaningful',\n",
       " 'insight',\n",
       " '.',\n",
       " 'involves',\n",
       " 'various',\n",
       " 'preprocessing',\n",
       " 'step',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'POS',\n",
       " 'tagging',\n",
       " ',',\n",
       " 'stop',\n",
       " 'word',\n",
       " 'removal',\n",
       " ',',\n",
       " 'stemming',\n",
       " ',',\n",
       " 'lemmatization',\n",
       " '.',\n",
       " 'text',\n",
       " 'preprocessed',\n",
       " ',',\n",
       " 'calculate',\n",
       " 'term',\n",
       " 'frequency',\n",
       " 'inverse',\n",
       " 'document',\n",
       " 'frequency',\n",
       " 'represent',\n",
       " 'document',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "829fcc3d-a153-4426-93c9-dbc0a204486d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Text analytics process analyzing unstructured text data derive meaningful insight . involves various preprocessing step tokenization , POS tagging , stop word removal , stemming , lemmatization . text preprocessed , calculate term frequency inverse document frequency represent document .'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join tokens into a single string for TF-IDF calculation\n",
    "preprocessed_text = \" \".join(lemmatized_tokens)\n",
    "preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a41cd37-b4a9-4a23-b216-c61375b58246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x28 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 28 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform([preprocessed_text])\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95b714ce-ab67-49b1-9c15-767fa2448598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['analytics', 'analyzing', 'calculate', 'data', 'derive',\n",
       "       'document', 'frequency', 'insight', 'inverse', 'involves',\n",
       "       'lemmatization', 'meaningful', 'pos', 'preprocessed',\n",
       "       'preprocessing', 'process', 'removal', 'represent', 'stemming',\n",
       "       'step', 'stop', 'tagging', 'term', 'text', 'tokenization',\n",
       "       'unstructured', 'various', 'word'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature names (terms)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3fad299-8509-452d-a7a9-131b0589e72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Text: Text analytics process analyzing unstructured text data derive meaningful insight . involves various preprocessing step tokenization , POS tagging , stop word removal , stemming , lemmatization . text preprocessed , calculate term frequency inverse document frequency represent document .\n"
     ]
    }
   ],
   "source": [
    "# Print Preprocessed Text\n",
    "print(\"Preprocessed Text:\", preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba577885-c6bc-4587-b1de-8ce25a8fc0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Representation:\n",
      "analytics: 0.1543033499620919\n",
      "analyzing: 0.1543033499620919\n",
      "calculate: 0.1543033499620919\n",
      "data: 0.1543033499620919\n",
      "derive: 0.1543033499620919\n",
      "document: 0.3086066999241838\n",
      "frequency: 0.3086066999241838\n",
      "insight: 0.1543033499620919\n",
      "inverse: 0.1543033499620919\n",
      "involves: 0.1543033499620919\n",
      "lemmatization: 0.1543033499620919\n",
      "meaningful: 0.1543033499620919\n",
      "pos: 0.1543033499620919\n",
      "preprocessed: 0.1543033499620919\n",
      "preprocessing: 0.1543033499620919\n",
      "process: 0.1543033499620919\n",
      "removal: 0.1543033499620919\n",
      "represent: 0.1543033499620919\n",
      "stemming: 0.1543033499620919\n",
      "step: 0.1543033499620919\n",
      "stop: 0.1543033499620919\n",
      "tagging: 0.1543033499620919\n",
      "term: 0.1543033499620919\n",
      "text: 0.4629100498862757\n",
      "tokenization: 0.1543033499620919\n",
      "unstructured: 0.1543033499620919\n",
      "various: 0.1543033499620919\n",
      "word: 0.1543033499620919\n"
     ]
    }
   ],
   "source": [
    "# Print TF-IDF Representation\n",
    "print(\"\\nTF-IDF Representation:\")\n",
    "for i, feature in enumerate(feature_names):\n",
    "    print(f\"{feature}: {tfidf_matrix[0, i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f35af6c-3375-4618-ba1a-2af1381a4f08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
